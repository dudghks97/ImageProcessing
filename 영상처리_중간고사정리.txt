<3주차정리>
1. CV_00_x_*
opencv 모듈을 통한 영상 파일 읽고 쓰기
- cv.imreadfilename, flags) => filename : 파일명 / flags : 읽기 모드 0 = Gray, 1= Color, -1 = Unchanged
- cv.imshow(title, img)
- cv.imwrite(filename, img)

2. CV__01
반전(역상) 출력 : imageR = 255 - image

화면 밝기 조절 
1) 밝게 : image1 = image*1.5
2) 어둡게 : image2 = image/1.5

*image의 데이터타입이 float형이어야 한다. imageF = image/255 연산 필요

cv.threshold() 메소드 : 255보다 큰 값을 255로 표현
ex) cv.threshold(src, dst, thresh, maxval, type) 
=> src : 입력파일명, dst : 출력파일명, thresh : threshold 값, maxval : , type : ThRESH_TRUNC

단계2의 오류와 같이 uint8의 데이터가 float64로 변환이 되어버림 => 이런식으로 밝기 조정하지말고
# 위의 오류는 다음과 같이 해결이 가능함
1) np.clip 사용
image1 = (np.clip(255*(image/255 * 1.5), 0, 255)).astype('uint8')
image2 = np.clip(255*(image/255 / 1.5), 0, 255).astype('uint8')

2) cv.threshold 사용
cv.threshold() 메소드 : 255보다 큰 값을 255로 표현
ex) cv.threshold(src, dst, thresh, maxval, type) 
=> src : 입력파일명, dst : 출력파일명, thresh : threshold 값, maxval : , type : THRESH_TRUNC
THRESH_TRUNC 가 thresh 이상의 모든 값을 thresh 값으로 바꿈

3. CV_02_ColorImage
영상의 RGB 데이터 분할
1) split, merge 메소드
r, g, b = cv.split(img) : r, g, b 분할
img = cv.merge(r, g, b) : r, g, b 합병

2) python 슬라이싱
imgR = imgBlank.copy(); imgR[:, :, 0] = img[:, :, 0]    # r
imgG = imgBlank.copy(); imgG[:, :, 1] = img[:, :, 1]   # g
imgB = imgBlank.copy(); imgB[:, :, 2] = img[:, :, 2]    # b

3) plt.imshow(img, cmap)
cmap 에는 다양한 종류가 있음 그때그때 필요한거 찾아서 쓰면 될듯함

4. CV_03_Slicing
new_img = img => 원본 손상의 여지가 있음(메모리 공유)
new_img = img.copy() => 원본 손상의 여지가 없음(새로운 객체 생성)

(1) 이미지 슬라이싱(그냥 파이썬 슬라이싱 생각하면 됨)
img[row, col, ch]
img[:, col//2:] => 우측 반
img[:, :col//2] => 좌측 반

img[row//2:, :] => 하단 절반
img[:row//2, :] => 상단 절반

5. CV_04_1_video_read_make_time_lapse
(1) VideoCapture 관련 메소드 (공모전하면서 많이 본 친구들)
    videoCapture=cv.VideoCapture(): 비디오 객체(읽기용)를 생성한다.
    cv.VideoCapture.get(): 읽을 비디오 파일(비디오 객체)의 속성을 출력한다.
    cv.VideoWriter_fourcc(): 쓰기 용의 비디오 영상 코덱을 지정한다.
    쓰기용 객체=cv.VideoWriter(): 쓰기용의 비디오 객체를 생성한다.
    frame=videoCapture.read(): 한 프레임의 영상을 반환한다.

(2) 관련 파라미터(get(), set())
    CAP_PROP_FPS - frame per second
    CAP_PROP_FRAME_WIDTH, CAP_PROP_FRAME_HEIGHT - 영상의 가로, 세로 정보
    CAP_PROP_FOURCC - 4문자로 이루어진 CODEC.비디오 압축 및 해제 알고리즘
    CAP_PROP_FRAME_COUNT - 파일 안에 담긴 총 프레임 수
    CAP_PROP_POS_FRAMES - 현재 프레임 개수

(3) FPS(Frame Per Second)
원본 : 30 -> 수정본 : 60
결과 => 재생시간 2배 단축
※ 3주차 완료
=========================================================================
<4주차 정리>
1. CV_04_2_video_read_Jump_between_frames
비디오의 특정 프레임 추출

2. CV_04_3_video_read_play_backwards
역재생 방법 : 시작 프레임 = 맨 마지막 프레임 - 1
프레임 감소를 통해 역재생을 함
fps = capture.get(cv.CAP_PROP_FPS)
1000/(fps) => 프레임의 간격

3. CV_05_1_ROI
ROI(Region Of Interset)
영상에서 특정 영역을 마우스 드래그로 선택함
opencv에서는 selectROI 메소드로 해당 기능을 제공함

ROI로 선택한 영역 정보를 반환
selected = False
while selected == False:
    x, y, w, h = cv.selectROI(msg_str, img, showCrosshair=False)
    if x == 0 and y == 0 and w == 0 and h == 0:  # x좌표. y좌표, 넓이(가로). 높이(세로)
        print("'c' seems to be pressed...")
        continue
    else:
        print(f'ROI: x={x}, y={y}, w={w}, h={h}')
        break

roi = img[y:y + h, x:x + w]  # 원본 영상의 선택된 부분을 roi 변수 어레이에 복사해 넣는다.
위 드래그한 영역에 대한 정보를 저장함

cv.hconcat([img1, img2]) => 가로로 이어붙이기
cv.vconcat([img1, img2]) => 세로로 이어붙이기

4. CV_06_1_USB_Camera_Display
5. CV_06_2_USB_Camera_Saving
위 두 파일은 cv.VideoCapture 를 통해 로컬 컴퓨터에 연결된 카메라 영상을 다루는 파일들

6. CV_07_Trackbar_1,2
트랙바. 1번에서 발생하는 문제점을 해결한 것이 2번
딱히 적어둘만한건 없고 그때그때 가서 보면 될듯함(2번만)

트랙바 생성(아래는 Red 예시)

cv.createTrackbar ('R', 	# 트랙바 앞에 표시될 트랙바의 이름
    'image',	# 트랙바가 나타날 창의 이름
    0,			# 시작 당시의 슬라이더의 초기 위치
    255,		# 슬라이더의 최댓값. 최솟값은 0으로 고정.
    callBack_R)	    # 슬라이더가 움직일 때 호출될 콜백 함수의 이름.
                    # 첫 번째 파라미터: 트랙 바 위치. 두 번째 파라미터: 사용자 데이터.

7. CV_08_1_resize_flip_concat
영상의 크기 변화 : resize()
1) 고정된 크기 지정 방식
cv.resize(img, (x, y))
2) 비율(fx, fy) 로 지정
cv.resize(img, dsize=(0, 0), fx, fy)

영상 뒤집기
cv.flip(img, filpCode)
filpCode : 대칭 방향 지정
1 = 좌우 대칭, 0 = 상하 대칭, -1 = 좌우 & 상하 대칭

8. CV_08_2_Drawing_2d_primitives_with_keyInputs
다음 글자 선택에 따라 화면의 임의 위치에 도형을 그리거나 문자를 쓴다.
# p : circle 함수를 이용하여 10개의 파란 색 점(반지름 3)을 그린다.
# l : line 함수를 이용하여 초록 색 선을 1개 그린다.
# r : rectangle() 함수를 이용하여 붉은 색 사각형을 그린다.
# e : ellipse() 함수를 이용하여 남색 타원형을 그린다.
# t : text 'OpenCV'를 임의 색상으로 화면에 쓴다.
# c : 화면에서 그린 도형, 문자를 모두 지운다. 이후 새로 그릴 수 있다.
# esc: 프로그램 종료

key = cv.waitkey()
key = ord(key)		=> ex. key = ord('p') : circle 함수 호출

# 그리기에 사용된 함수들
cv.circle
cv.line
cv.rectangle
cv.ellipse
cv.putText
※ 4주차 완료
=========================================================================
<5주차 정리>
1. sf1_averaging_filter2D
    correlation 을 행하는 함수, filter2D
    dst	= cv.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]])
	src : 입력 영상
	dst : 출력 영상ㅇ
	ddepth : 출력 영상의 희망하는 depth
	kernel : 컨볼루션 커널, 2차원 행렬
	anchor : 커널의 상대적 중심점의 위치. default : (-1, -1)
	delta : 코릴레이션 연산 수행의 처리 결과(dst에 더해질 값)
	bordertype : 존재하지 않는 영역의 화소값을 가정하는 방법
관련 상세는 pdf


2. sf2_*_gaussian*d_draw_on_*D
가우시안 커널 함수
cv.getGaussianKernel(ksize, sigma, ktype)
ksize : kernel 사이즈, 홀수인 양수
sigma : 가우시안 표준 편차, 음수
ktype : filter type CV_32F / CV_64F 가 될수있음

3. sf4_GaussianBlur
가우시안 블러링 실습

4. sf5_filter2d_sepFilter2D
선형 분리가능 필터링 실습
cv.sepFilter2D()
※ 5주차 미완 함수 및 정의 정리 필요
=========================================================================
<6주차 정리>

=========================================================================
<7주차 정리>

* 감마변환(밝기 조절)
output = input^Γ, 	0<=input<=1 (0~1로 정규화된 입력에 대한 변환)

Γ > 1 : 어둡게 처리, 특히 어두운 부분을 더 어둡게. Γ값이 커질수록 더 어두워짐
	ex) 화소값이 255면 감마연산을해도 화소값이 같다. -> 해결방안 x
Γ < 1 : 밝게 처리, 특히 어두운 부분을 더 밝게. Γ값이 작을수록 더 밝아짐

전역적으로 같은 비율로 밝아지는건 아니다. 


* for루프 사용은 좋지 않다.
 시간대비 효율이 안좋아 실용화 x


* 시그모이드 변환
m : 중심값. threshold라고도함
w : 기울기 경사값(?). 범위는 0~1이며 w값이 커질수록 기울기 경사가 급해짐
e : ?



* 히스토그램 : 영상의 통계적인 계조 분포
0~255의 픽셀의 각각의 값에 대한 개수를 그래프로 나타냄


* 히스토그램 스트레칭 : 영상의 대조비를 강화
 imadjust  함수 이용

- 넓은 폭을 사용할 경우 : ?
- 좁은 폭을 사용할 경우 : 특정부분이 진해짐.
 비교해보기



* 히스토그램 평활화 : 영상의 계조 분포를 고르게하는 작업
 -> ㅡ자로 완전 평평하게는 불가능. 하지만 최대한 평평하게는 만들수있다.
    컬러 영상은 평활화 불가능.
1단계 : 히스토그램(계조치 분포함수)을 구함
2단계 : 히스토그램의 누적분포함수를 구함
3단계 : 누적분포함수를 제일 큰 값(화소의 개수)으로 나누어 정규화
4단계 : 정규화 누적 분포함수에 최대화소값를 곱해 반올림한 매핑함수를 만듬
5단계 : 출력화소값으로 변환

문제점 
1. 중간중간에 빈 화소가 존재하게됨
     -> 그라데이션 효과가 부족해짐 -> 영상 품질 저하
2. spike현상 발생 : 특정 화소의 개수가 매우 많을 경우(quantum jump)
    -> 해결책 : jump의 정도를 낮추어 중간에 빈 화소를 줄임 


* 히스토그램의 명세화 : pass(안봐도 됨)
- 히스토그램의 분포를 자기가 원하는대로 바꿀수 있음
- 하지만 이 기법을 사용함으로 얻을 수 있는게...??




* 샤프닝 마스크 : 영상의 선명도 개선 기법
 마하 효과 : 원함수에 원함수를 2차미분한 함수값을 빼면 명암이 강조되는 효과가 
               발생하는데 이를 마하 효과라 한다.

	-> 원함수 - 2차미분(라플라시안 커널)


* 언샤프 마스킹 : 블러링된 영상을 이용하여 영상을 선명하게 만드는 알고리즘